<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux 系统优化指令杂记]]></title>
    <url>%2F2018%2F09%2F24%2Flinux-system-profile-command%2F</url>
    <content type="text"><![CDATA[系统优化的前 5 分钟使用如下指令了解机器的整体运行情况, 此处有指令的中文解释 uptime 检查系统是否宕机重启 dmesg | tail 查看 dmesg 是否有系统层面错误日志 vmstat 1 检查 cpu 的负载情况, 是否存在 cpu 饱和 mpstat -P ALL 1 检查CPU是否存在负载不均衡; 单个过于忙碌的CPU可能意味着整个应用只有单个线程在工作 pidstat 1 观察随时间变化的 cpu、内存等信息 iostat -xz 1 弄清块设备（磁盘）的状况, 包括工作负载和处理性能 free -m 查看剩余内存, 文件和 IO 缓存大小 sar -n DEV 1 检查网络流量的工作负载：rxkB/s和txkB/s, 以及它是否达到限额了 sar -n TCP,ETCP 1 查看系统网络负载, 过多重传可能是服务器过载开始丢包了 top 没什么好多, 大家都会用的 top 各个指标含义 Cpu(s)：表示这一行显示CPU总体信息 0.0%us：用户态进程占用CPU时间百分比, 不包含renice值为负的任务占用的CPU的时间。 0.7%sy：内核占用CPU时间百分比 0.0%ni：改变过优先级的进程占用CPU的百分比 99.3%id：空闲CPU时间百分比 0.0%wa：等待I/O的CPU时间百分比 0.0%hi： CPU硬中断时间百分比 0.0%si： CPU软中断时间百分比 0.0%st: 超线程开启时候, 线程等待另外一个虚拟核完成任务的时间百分比 note：这里显示数据是所有cpu的平均值, 如果想看每一个cpu的处理情况, 按1即可；折叠, 再次按1 中断硬中断 硬中断是由硬件产生的，比如，像磁盘，网卡，键盘，时钟等。每个设备或设备集都有它自己的IRQ（中断请求）。基于IRQ，CPU可以将相应的请求分发到对应的硬件驱动上（注：硬件驱动通常是内核中的一个子程序，而不是一个独立的进程）。 处理中断的驱动是需要运行在CPU上的，因此，当中断产生的时候，CPU会中断当前正在运行的任务，来处理中断。在有多核心的系统上，一个中断通常只能中断一颗CPU（也有一种特殊的情况，就是在大型主机上是有硬件通道的，它可以在没有主CPU的支持下，可以同时处理多个中断。）。 硬中断可以直接中断CPU。它会引起内核中相关的代码被触发。对于那些需要花费一些时间去处理的进程，中断代码本身也可以被其他的硬中断中断。 对于时钟中断，内核调度代码会将当前正在运行的进程挂起，从而让其他的进程来运行。它的存在是为了让调度代码（或称为调度器）可以调度多任务。 软中断 软中断的处理非常像硬中断。然而，它们仅仅是由当前正在运行的进程所产生的。 通常，软中断是一些对I/O的请求。这些请求会调用内核中可以调度I/O发生的程序。对于某些设备，I/O请求需要被立即处理，而磁盘I/O请求通常可以排队并且可以稍后处理。根据I/O模型的不同，进程或许会被挂起直到I/O完成，此时内核调度器就会选择另一个进程去运行。I/O可以在进程之间产生并且调度过程通常和磁盘I/O的方式是相同。 软中断仅与内核相联系。而内核主要负责对需要运行的任何其他的进程进行调度。一些内核允许设备驱动的一些部分存在于用户空间，并且当需要的时候内核也会调度这个进程去运行。 软中断并不会直接中断CPU。也只有当前正在运行的代码（或进程）才会产生软中断。这种中断是一种需要内核为正在运行的进程去做一些事情（通常为I/O）的请求。有一个特殊的软中断是Yield调用，它的作用是请求内核调度器去查看是否有一些其他的进程可以运行。 释疑 对于软中断，I/O 操作是否是由内核中的 I/O 设备驱动程序完成？ 对于 I/O 请求，内核会将这项工作分派给合适的内核驱动程序，这个程序会对 I/O 进行队列化，以可以稍后处理（通常是磁盘I/O），或如果可能可以立即执行它。通常，当对硬中断进行回应的时候，这个队列会被驱动所处理。当一个 I/O 请求完成的时候，下一个在队列中的 I/O 请求就会发送到这个设备上。 软中断所经过的操作流程是比硬中断的少吗？换句话说，对于软中断就是：进程 -&gt; 内核中的设备驱动程序；对于硬中断：硬件 -&gt; CPU 内核中的设备驱动程序？ 是的，软中断比硬中断少了一个硬件发送信号的步骤。产生软中断的进程一定是当前正在运行的进程，因此它们不会中断CPU。但是它们会中断调用代码的流程。 如果硬件需要 CPU 去做一些事情，那么这个硬件会使 CPU 中断当前正在运行的代码。而后 CPU 会将当前正在运行进程的当前状态放到堆栈（stack）中，以至于之后可以返回继续运行。这种中断可以停止一个正在运行的进程；可以停止正处理另一个中断的内核代码；或者可以停止空闲进程。 查看 cpu 超线程和 cpu 物理核对应关系123456789101112131415161718192021222324252627282930~$ lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 2On-line CPU(s) list: 0,1Thread(s) per core: 1Core(s) per socket: 2Socket(s): 1NUMA node(s): 1Vendor ID: GenuineIntelCPU family: 6Model: 61Model name: Intel(R) Core(TM) i5-5257U CPU @ 2.70GHzStepping: 4CPU MHz: 2699.998BogoMIPS: 5399.99Hypervisor vendor: KVMVirtualization type: fullL1d cache: 32KL1i cache: 32KL2 cache: 256KL3 cache: 3072KNUMA node0 CPU(s): 0,1~$ cat /sys/devices/system/node/node1/cpulist1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39~$ cat /sys/devices/system/node/node0/cpulist0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38 机器总共有 2 个物理核心，每个物理核心有 10 个逻辑核，每个逻辑核有 2 个超线程 查看进程和 cpu 亲缘性绑定关系1234567891011ps -eo pid,argssrpid - 进程IDargs - 该进程执行时传入的命令行参数psr - 分配给进程的逻辑CPU~$ ps -eo pid,argssr | grep nginx9073 nginx: master process /usr/ 19074 nginx: worker process 09075 nginx: worker process 19076 nginx: worker process 29077 nginx: worker process 3 查看中断号和 cpu 绑定关系1234567891011121314151617~$ cat /proc/interrupts CPU0 CPU1 162: 1051061576 0 IR-PCI-MSI-edge eth0-TxRx-0 163: 85025461 133849653 IR-PCI-MSI-edge eth0-TxRx-1 164: 88387458 0 IR-PCI-MSI-edge eth0-TxRx-2 165: 138497867 0 IR-PCI-MSI-edge eth0-TxRx-3 166: 187011870 0 IR-PCI-MSI-edge eth0-TxRx-4 167: 71803161 35003925 IR-PCI-MSI-edge eth0-TxRx-5 168: 65314317 0 IR-PCI-MSI-edge eth0-TxRx-6 169: 64069078 0 IR-PCI-MSI-edge eth0-TxRx-7 170: 138158880 0 IR-PCI-MSI-edge eth0-TxRx-8 171: 40424137 20524266 IR-PCI-MSI-edge eth0-TxRx-9 172: 134531725 0 IR-PCI-MSI-edge eth0-TxRx-10~$ sudo cat /proc/irq/165/smp_affinity00000000,00000000,00000000,00000000,00000000,00000008 首先查看系统所有中断号，查看多对列网卡 eth0 的中断号查看中断号分配的 cpu, 0x00000008 代表 cpu 8 others123ethtools -S eth0 查看网络的队列信息ethanol -i eth0 查看网卡信息lspci -vvv 查看pci 相关信息 iperf 网卡测试-P 指定一个并发, 如果指定多个并发，统计信息不友好12345server:iperf -sclient:iperf -c 10.200.136.41 -p 5001 -P 1 -t 60 -i 1 查看网卡情况netstat 查看 Errorsifconfig 查看 dropped 数量1234567891011121314151617181920~$ watch &apos;netstat -s --udp&apos;Udp: 437.0k/s packets received 0.0/s packets to unknown port received. 386.9k/s packet receive errors 0.0/s packets sent RcvbufErrors: 123.8k/s SndbufErrors: 0 InCsumErrors: 0~$ ifconfigenp0s8: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.56.101 netmask 255.255.255.0 broadcast 192.168.56.255 inet6 fe80::b5e6:56d6:48dd:e317 prefixlen 64 scopeid 0x20&lt;link&gt; ether 08:00:27:e6:c8:ac txqueuelen 1000 (Ethernet) RX packets 71 bytes 20634 (20.1 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 81 bytes 13593 (13.2 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 命令助记]]></title>
    <url>%2F2018%2F09%2F24%2Flinux-command-note%2F</url>
    <content type="text"><![CDATA[print all system information1uname -a kernel version:1uname -r see hardware info.1cat /proc/meminfo cat /proc/cpuinfo count line1find . -name &apos;\*.c&apos; | xargs wc -l &#123;&#125;\; yum remove without dependency1sudo rpm -e --nodeps vim-common-7.4.160-1.el7.x86_64 fio test1sudo /usr/local/bin/fio --filename=/dev/sda --direct=1 --rw=randrw --refill_buffers --norandommap --randrepeat=0 --ioengine=libaio --bs=4k --rwmixread=100 --iodepth=16 --numjobs=16 --runtime=1000 --group_reporting --name=4ktest docker expose port to host machine1docker run -p 8080:3000 my-image docker get running container bash cmd1docker exec -it contained bash tcpdump1sudo tcpdump -i any port 9200 -w o.pcap 批量结束进程1kill -9 `ps -ef|grep nginx|grep -v grep |awk &apos;&#123;print $2&#125;&apos;` 查看进程占用端口123456ps -ef | grep processnamenetstat -nap | grep pidlsof -i:9090pwdx 9090lsof -P 9090 | grep cwd vim replace1: %s/\(randrecord\.get(&apos;ip&apos;)\)/ptest\.\1/g 将文件中的所有 randrecord.get(‘ip’) 替换为 test.randrecord.get(‘ip’)，即使用 \1 \2 等可以匹配前面第几个括号内的内容，此括号需要使用 反斜杠 转意 查看 glibc 版本1strings /lib64/libc.so.6 |grep GLIBC linux 将标出输出重定向到 /dev/null12&gt;&amp; 1 awk 打印奇偶行1awk &apos;&#123;print $0 &gt; NR%2&#125;&apos; file sort by frequence1cat tmp.txt| sort | uniq -c | sort -k1,1nr | head -30 &gt; stoplist.txt filter by stoplist1tr &apos; &apos; &apos;\n&apos; &lt; stoplist.txt | grep -vwFf - tmp.txt 字符串拼接1ps -ef | grep zicogo | awk &apos;BEGIN&#123;sum=&quot;&quot;&#125;&#123;sum=($2&quot;,&quot;sum)&#125;END&#123;print sum&#125;&apos; 按组统计求和1awk &apos;&#123;s[$1] += $2; a[$1] += $3 &#125;END&#123; for(i in s)&#123; printf &quot;%-50s %-20d %-20d\n&quot;, i,s[i],a[i] &#125; &#125;&apos; upstats-2017-07-05-15-05.log+ 查看某个库的版本号1ldconfig -p | grep libssl 删除 archlinux 软件包1pacman -Scc history clean1cat .zsh_history | awk &apos;BEGIN&#123;FS=&quot;&quot;&#125;&#123;if (NF &gt; 40 ) print ;&#125;&apos; &gt;&gt; .zsh_history_new brew install1brew install vim --with-lua --with-override-system-vi --build-from-source global floder sed1sed -i &quot;s/TINY/NOX/g&quot; `grep -R TINY -rl ./` 批量查找替换1find CHANGELOG.md -type f -exec vim +&quot;retab | wq&quot; &#123;&#125; \; 查看用户所属组1id -g -n $whoami 列出 osx 系统的 java 版本1/usr/libexec/java_home -V 列出 java 的信任证书1keytool -list -keystore /Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/security/cacerts java 导入证书1keytool -import -trustcacerts -file [certificate] -alias [alias] -keystore $JAVA_HOME/lib/security/cacerts vim highlight1:so $VIMRUNTIME/syntax/hitest.vim check cpu info123456789sudo dmidecode -t 4 | grep -E &apos;Socket Designation|Count&apos; Socket Designation: CPU1 Core Count: 8 Thread Count: 16 Socket Designation: CPU2 Core Count: 8 Thread Count: 16lscpu awk 和 grep 日志统计分析12cat nginx/logs/access.log | grep &quot;17/Sep&quot; | grep -v &apos;2\.43&apos; | awk &apos;&#123;if ($11 &gt; 1) print $0&#125;&apos;cat nginx/logs/access.log | grep &quot;17/Sep&quot; | grep -v &apos;2\.43&apos; | awk &apos;BEGIN&#123;a=0&#125;&#123;if ($11&gt;0+a) a=$11&#125; END&#123;print a&#125;&apos; centos 查看某个库是哪个 package 提供的1yum whatprovides libpci.so.3 查看 PPID1top -&gt; G -&gt; 2]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[updns QPS 异常问题排查]]></title>
    <url>%2F2018%2F09%2F24%2Fupdns-qps-tracing%2F</url>
    <content type="text"><![CDATA[环境问题排查 系统: 系统版本, 内核版本 cpu: 物理核心数, 物理核数,逻辑核数 内存: 内存大小 网卡: 网卡是否是万兆, 驱动型号 updns 版本确认（排查是否最近代码导致） 以前压测过的版本回退 v0.03 使用最近版本测试 系统各种参数优化确认 sendmmsg recvmmsg 多线程发包 so_reuseport 绑定网卡亲缘性 系统参数调优化 查看软件终端, 查看 cpu 绑定是否生效 使用系统工具确认压测机器是否正常 iperf 网络ok, 吞吐量OK, QPS: 60s 400W QPS, 800Mb/s udp sender 查看发包 80w/s, 系统占用低 perf spin_irq_lock 60% 查看网卡的收包, 接包, 丢包情况 被测端和压测端的情况]]></content>
  </entry>
  <entry>
    <title><![CDATA[nginx server locaton 匹配顺序]]></title>
    <url>%2F2018%2F09%2F24%2Fnginx-server-locaton-re-match%2F</url>
    <content type="text"><![CDATA[server name 完全匹配 通配符在前面，*.tesetwb.com 通配符在后面，www.testwb.* 正则表达式匹配 (.*)?anyfeel.cn location 完全匹配，= or / 大小写敏感，~ 大小写不敏感，~* 前半部分匹配，^~ @location, 表示只能用于 nginx 内部跳转]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 模块初始化过程]]></title>
    <url>%2F2018%2F09%2F24%2Fnginx-module-init%2F</url>
    <content type="text"><![CDATA[初始化核心函数ngx_init_cycle()(ngx_cycle.c:275) -&gt; ngx_conf_parse()(ngx_conf_file.c:) -&gt; ngx_conf_handler() 初始化步骤 modules 和序号绑定关系123456789101112131415ngx_int_tngx_preinit_modules(void)&#123; ngx_uint_t i; for (i = 0; ngx_modules[i]; i++) &#123; ngx_modules[i]-&gt;index = i; ngx_modules[i]-&gt;name = ngx_module_names[i]; &#125; ngx_modules_n = i; ngx_max_module = ngx_modules_n + NGX_MAX_DYNAMIC_MODULES; return NGX_OK;&#125; ngx_init_cycle 初始化核心模块 12345678910111213141516171819202122232425262728293031323334353637383940...for (i = 0; cycle-&gt;modules[i]; i++) &#123; if (cycle-&gt;modules[i]-&gt;type != NGX_CORE_MODULE) &#123; continue; &#125; module = cycle-&gt;modules[i]-&gt;ctx; if (module-&gt;create_conf) &#123; rv = module-&gt;create_conf(cycle); if (rv == NULL) &#123; ngx_destroy_pool(pool); return NULL; &#125; cycle-&gt;conf_ctx[cycle-&gt;modules[i]-&gt;index] = rv; &#125;&#125;...for (i = 0; cycle-&gt;modules[i]; i++) &#123; if (cycle-&gt;modules[i]-&gt;type != NGX_CORE_MODULE) &#123; // NGX_CORE_MODULE 核心模块 continue; &#125; module = cycle-&gt;modules[i]-&gt;ctx; if (module-&gt;init_conf) &#123; if (module-&gt;init_conf(cycle, cycle-&gt;conf_ctx[cycle-&gt;modules[i]-&gt;index]) // 初始化 == NGX_CONF_ERROR) &#123; environ = senv; ngx_destroy_cycle_pools(&amp;conf); return NULL; &#125; &#125;&#125;... 调用 ngx_events_block 来解析具体模块如配置和指令, 以 event 模块为例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354static char *ngx_events_block(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)&#123; ... *(void **) conf = ctx; for (i = 0; cf-&gt;cycle-&gt;modules[i]; i++) &#123; if (cf-&gt;cycle-&gt;modules[i]-&gt;type != NGX_EVENT_MODULE) &#123; continue; &#125; m = cf-&gt;cycle-&gt;modules[i]-&gt;ctx; if (m-&gt;create_conf) &#123; (*ctx)[cf-&gt;cycle-&gt;modules[i]-&gt;ctx_index] = m-&gt;create_conf(cf-&gt;cycle); // 为每个 event 模块分配内存 if ((*ctx)[cf-&gt;cycle-&gt;modules[i]-&gt;ctx_index] == NULL) &#123; return NGX_CONF_ERROR; &#125; &#125; &#125; pcf = *cf; cf-&gt;ctx = ctx; cf-&gt;module_type = NGX_EVENT_MODULE; cf-&gt;cmd_type = NGX_EVENT_CONF; rv = ngx_conf_parse(cf, NULL); // 解析 event 模块，如 `work_connections` *cf = pcf; if (rv != NGX_CONF_OK) &#123; return rv; &#125; for (i = 0; cf-&gt;cycle-&gt;modules[i]; i++) &#123; if (cf-&gt;cycle-&gt;modules[i]-&gt;type != NGX_EVENT_MODULE) &#123; continue; &#125; m = cf-&gt;cycle-&gt;modules[i]-&gt;ctx; if (m-&gt;init_conf) &#123; rv = m-&gt;init_conf(cf-&gt;cycle, (*ctx)[cf-&gt;cycle-&gt;modules[i]-&gt;ctx_index]); // 和指令默认值对比，设置指令的值 if (rv != NGX_CONF_OK) &#123; return rv; &#125; &#125; &#125; return NGX_CONF_OK;&#125;]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP 连接状态整理]]></title>
    <url>%2F2018%2F09%2F24%2Ftcp-connection-status%2F</url>
    <content type="text"><![CDATA[要点 五层架构与七层架构 链路层作用 ARP，以太网包格式 IP/TCP 格式 TCP 状态机及常用的错误码，time_wait 相关系，SO_RESUSEADDR 作用。 NAGEL 算法(TCP_NODELAY关闭NAGEL)滑动窗口拥塞避免（慢启动），快速重传与快速恢复，选择重传 四种定时器的作用 ACK 定时器，persist 定时器，keep-alive 定时器，2MSL 定时器 使用 TCPDUMP 和应用程序分析 TCP 状态机 note:so_linger 作用： 发送 RST 包来断开连接，而不是发送 FIN. connect resty by peer含义本端向对端发送数据，但对端无法识别该连接，返回一个 RST 强制关闭连接 原因 当尝试和未开放的服务器端口建立tcp连接时，服务器tcp将会直接向客户端发送reset报文，表现状态是连接决绝。 双方之前已经正常建立了通信通道，也可能进行过了交互，当某一方在交互的过程中发生了异常，如崩溃等，异常的一方会向对端发送reset报文，通知对方将连接关闭 当收到TCP报文，但是发现该报文不是已建立的TCP连接列表可处理的，则其直接向对端发送reset报文 ack报文丢失，并且超出一定的重传次数或时间后，会主动向对端发送reset报文释放该TCP连接 一端设置了 SO_LINGER 选项来关闭连接，则对端会收到 connection by peer 错误来关闭连接 TCP 状态机]]></content>
      <tags>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 磁盘调整]]></title>
    <url>%2F2018%2F09%2F23%2Fadjust-disk-partition-size%2F</url>
    <content type="text"><![CDATA[磁盘工具 parted/fdisk/gdisk/ blkid note: 注意区分 PARTUUID 和 UUID gdisk sort 可以调整分区序号 磁盘格式化 EFI 分区格式化1mkfs.fat -F32 /dev/sdxY -&gt; EFI 分区格式化 如果没有 mkfs.fat 则安装 dosfstools 分区格式化1mkfs.ext4 /dev/sda1 磁盘启动管理 安装 bootctl 1bootctl —path=/mnt/boot install 增加磁盘启动选项 1/boot/loader/entries/arch.conf 这里写入的是 root 分区的 PARTUUID 磁盘分区大小调整(resize) 先删除原有分区，然后再重新建立（启动区块号不能变，否则会丢失数据） 使用 resize2fs /dev/sda1 来重新调整分区大小 最后需要解决 EFI loader 中 PARTUUID，PARTUUID 可能会有变更]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 pyenv 构建线上 python 环境]]></title>
    <url>%2F2018%2F09%2F23%2Fdeploy-python-program-by-pyenv%2F</url>
    <content type="text"><![CDATA[使用 pyenv 部署 python 线上环境当生产服务器因权限问题或者系统版本阉割出现 python 依赖问题时，可以使用 pyenv 安装方法 下载 pyenv. 1$ git clone https://github.com/yyuu/pyenv.git ~/.pyenv 设置PYENV_ROOT 为 pyenv 安装路径, 添加 $PYENV_ROOT/bin 至环境变量 12$ echo &apos;export PYENV_ROOT=&quot;$HOME/.pyenv&quot;&apos; &gt;&gt; ~/.bash_profile$ echo &apos;export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;&apos; &gt;&gt; ~/.bash_profile 开启 pyenv shims 和自动补全 1$ echo &apos;eval &quot;$(pyenv init -)&quot;&apos; &gt;&gt; ~/.bash_profile 重启 shell 让 pyenv 生效 1$ exec $SHELL 安装需要的 python 版本 至 $PYENV_ROOT/versions 目录 1$ pyenv install 2.7.8 pyenv 常用命令12345pyenv install 2.7.5pyenv versionspyenv versionpyenv local 2.7.5pyenv shell 2.7.5]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[run nsq by docker]]></title>
    <url>%2F2018%2F09%2F23%2Frun-nsq-by-docker%2F</url>
    <content type="text"><![CDATA[componentsnsqdnsqd is the daemon that receives, queues, and delivers messages to clients.two tcp ports: one for clients and one for HTTP API nsqlookupdthe daemon that manages topology information.Clients query nsqlookupd to discover nsqd producers for a specific topic and nsqd nodes broadcasts topic and channel information.two interfaces: A TCP interface which is used by nsqd for broadcasts and an HTTP interface for clients to perform discovery and administrative actions. nsqadminWeb UI to view aggregated cluster stats in realtime and perform various administrative tasks run nsqget nsq docker image1docker pull nsqio/nsq run nsqlookupd1docker run --name lookupd -d -p 4160:4160 -p 4161:4161 nsqio/nsq /nsqlookupd run nsqd get docker host’s ip 1ifconfig | grep docker addr -&gt; 172.17.0.1 run nsqd container 12docker run --name nsqd -d -p 4150:4150 -p 4151:4151 nsqio/nsq /nsqd --broadcast-address=&lt;host&gt; --lookupd-tcp-address=&lt;host&gt;:&lt;port&gt; eg:12docker run --name nsqd -d -p 4150:4150 -p 4151:4151 nsqio/nsq /nsqd --broadcast-address=172.17.0.1 --lookupd-tcp-address=172.17.0.1:4160 note:a. no care for 4150 and 4151b. –broadcast-address set to the docker addrc. –lookupd-tcp-address set to the nsqlookupd http listen port, here is 4161 run nsqadmin1docker run -d --name nsqadmin -p 4171:4171 nsqio/nsq /nsqadmin --lookupd-http-address=172.17.0.1:4161]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 编码理解]]></title>
    <url>%2F2018%2F09%2F23%2FLinux-encode-thinking%2F</url>
    <content type="text"><![CDATA[系统的编码方式在我所使用的 centos6 中使用 echo $LANG 查看编码系统的编码方式决定了在终端中录入的内容的编码方式 编辑器所使用的文件编码方式在 vim 中，set fileencoding 查看当前编码方式编辑器的编码方式决定了在代码中录入内容的编码方式，如 a[‘key’] = value，此时的 ‘key’ 字段按照 fileencoding 的方式编码 代码中使用的编码方式例如 if a == b : pass，此内容的编码方式 从文件中读取的内容的编码方式例如：12redis_cli&gt;&gt; set “marco:domains” “basic.b0.upaiyun.com” “basic&quot; 此写入redis的内容，根据终端的编码方式决定， 我的系统默认是utf-8 ，所以此处也是utf-8内容 解释器的编码方式python 解释器使用 unicode 编码方式解释执行 note:在我使用的环境中为 centos + vim 开发环境，处处是 utf-8 编码 python 编码中文处理 总体思路：程序整体内部使用 python 解释器的内建 ascii, 在文件落地本地存储的时候再转存为 utf-8 在处理中文字符串的时候，由于系统编码的差异直接使用 string 类型表示中文的时候错误，使用 unicode 表示。 使用 str.decode(‘utf-8’)转换为 unicode object]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netcat skills]]></title>
    <url>%2F2018%2F09%2F23%2Fnetcat-skills%2F</url>
    <content type="text"><![CDATA[Linux netcat 命令实例：端口扫描端口扫描经常被系统管理员和黑客用来发现在一些机器上开放的端口，帮助他们识别系统中的漏洞。 $nc -z -v -n 172.31.100.7 21-25 可以运行在TCP或者UDP模式，默认是TCP，-u参数调整为udp. z 参数告诉netcat使用0 IO,连接成功后立即关闭连接， 不进行数据交换 v 参数指使用冗余选项 n 参数告诉netcat 不要使用DNS反向查询IP地址的域名 这个命令会打印21到25 所有开放的端口。Banner是一个文本，Banner是一个你连接的服务发送给你的文本信息。当你试图鉴别漏洞或者服务的类型和版本的时候，Banner信息是非常有用的。但是，并不是所有的服务都会发送banner。 一旦你发现开放的端口，你可以容易的使用netcat 连接服务抓取他们的banner。 $ nc -v 172.31.100.7 21 netcat 命令会连接开放端口21并且打印运行在这个端口上服务的banner信息。 Chat Server假如你想和你的朋友聊聊，有很多的软件和信息服务可以供你使用。但是，如果你没有这么奢侈的配置，比如你在计算机实验室，所有的对外的连接都是被限制的，你怎样和整天坐在隔壁房间的朋友沟通那？不要郁闷了，netcat提供了这样一种方法，你只需要创建一个Chat服务器，一个预先确定好的端口，这样子他就可以联系到你了。 Server$nc -l 1567netcat 命令在1567端口启动了一个tcp 服务器，所有的标准输出和输入会输出到该端口。输出和输入都在此shell中展示。 Client$nc 172.31.100.7 1567不管你在机器B上键入什么都会出现在机器A上。 文件传输大部分时间中，我们都在试图通过网络或者其他工具传输文件。有很多种方法，比如FTP,SCP,SMB等等，但是当你只是需要临时或者一次传输文件，真的值得浪费时间来安装配置一个软件到你的机器上嘛。假设，你想要传一个文件file.txt 从A 到B。A或者B都可以作为服务器或者客户端，以下，让A作为服务器，B为客户端。 Server$nc -l 1567 &lt; file.txtClient$nc -n 172.31.100.7 1567 &gt; file.txt这里我们创建了一个服务器在A上并且重定向netcat的输入为文件file.txt，那么当任何成功连接到该端口，netcat会发送file的文件内容。 在客户端我们重定向输出到file.txt，当B连接到A，A发送文件内容，B保存文件内容到file.txt. 没有必要创建文件源作为Server，我们也可以相反的方法使用。像下面的我们发送文件从B到A，但是服务器创建在A上，这次我们仅需要重定向netcat的输出并且重定向B的输入文件。 B作为Server Server$nc -l 1567 &gt; file.txtClientnc 172.31.100.23 1567 &lt; file.txt 目录传输发送一个文件很简单，但是如果我们想要发送多个文件，或者整个目录，一样很简单，只需要使用压缩工具tar，压缩后发送压缩包。 如果你想要通过网络传输一个目录从A到B。 Server$tar -cvf – dir_name | nc -l 1567Client$nc -n 172.31.100.7 1567 | tar -xvf -这里在A服务器上，我们创建一个tar归档包并且通过-在控制台重定向它，然后使用管道，重定向给netcat，netcat可以通过网络发送它。 在客户端我们下载该压缩包通过netcat 管道然后打开文件。 如果想要节省带宽传输压缩包，我们可以使用bzip2或者其他工具压缩。 Server$tar -cvf – dir_name| bzip2 -z | nc -l 1567通过bzip2压缩 Client$nc -n 172.31.100.7 1567 | bzip2 -d |tar -xvf -使用bzip2解压 加密你通过网络发送的数据如果你担心你在网络上发送数据的安全，你可以在发送你的数据之前用如mcrypt的工具加密。 服务端$nc localhost 1567 | mcrypt –flush –bare -F -q -d -m ecb &gt; file.txt使用mcrypt工具加密数据。 客户端$mcrypt –flush –bare -F -q -m ecb &lt; file.txt | nc -l 1567使用mcrypt工具解密数据。 以上两个命令会提示需要密码，确保两端使用相同的密码。 这里我们是使用mcrypt用来加密，使用其它任意加密工具都可以。 流视频虽然不是生成流视频的最好方法，但如果服务器上没有特定的工具，使用netcat，我们仍然有希望做成这件事。 服务端$cat video.avi | nc -l 1567这里我们只是从一个视频文件中读入并重定向输出到netcat客户端$nc 172.31.100.7 1567 | mplayer -vo x11 -cache 3000 -这里我们从socket中读入数据并重定向到mplayer。 克隆一个设备如果你已经安装配置一台Linux机器并且需要重复同样的操作对其他的机器，而你不想在重复配置一遍。不在需要重复配置安装的过程，只启动另一台机器的一些引导可以随身碟和克隆你的机器。 克隆Linux PC很简单，假如你的系统在磁盘/dev/sda上 Server$dd if=/dev/sda | nc -l 1567Client$nc -n 172.31.100.7 1567 | dd of=/dev/sdadd是一个从磁盘读取原始数据的工具，我通过netcat服务器重定向它的输出流到其他机器并且写入到磁盘中，它会随着分区表拷贝所有的信息。但是如果我们已经做过分区并且只需要克隆root分区，我们可以根据我们系统root分区的位置，更改sda 为sda1，sda2.等等。 打开一个shell我们已经用过远程shell-使用telnet和ssh，但是如果这两个命令没有安装并且我们没有权限安装他们，我们也可以使用netcat创建远程shell。 假设你的netcat支持 -c -e 参数(默认 netcat) Server$nc -l 1567 -e /bin/bash -iClient$nc 172.31.100.7 1567这里我们已经创建了一个netcat服务器并且表示当它连接成功时执行/bin/bash 假如netcat 不支持-c 或者 -e 参数（openbsd netcat）,我们仍然能够创建远程shell Server``$mkfifo /tmp/tmp_fifo $cat /tmp/tmp_fifo | /bin/sh -i 2&gt;1 | nc -l 1567 &gt; /tmp/tmp_fifo``这里我们创建了一个fifo文件，然后使用管道命令把这个fifo文件内容定向到shell 2>&amp;1中。是用来重定向标准错误输出和标准输出，然后管道到netcat 运行的端口1567上。至此，我们已经把netcat的输出重定向到fifo文件中。 说明： 从网络收到的输入写到fifo文件中 cat 命令读取fifo文件并且其内容发送给sh命令 sh命令进程受到输入并把它写回到netcat。 netcat 通过网络发送输出到client 至于为什么会成功是因为管道使命令平行执行，fifo文件用来替代正常文件，因为fifo使读取等待而如果是一个普通文件，cat命令会尽快结束并开始读取空文件。 在客户端仅仅简单连接到服务器 Client$nc -n 172.31.100.7 1567你会得到一个shell提示符在客户端 反向shell 反向shell是指在客户端打开的shell。反向shell这样命名是因为不同于其他配置，这里服务器使用的是由客户提供的服务。 服务端$nc -l 1567在客户端，简单地告诉netcat在连接完成后，执行shell。 客户端$nc 172.31.100.7 1567 -e /bin/bash现在，什么是反向shell的特别之处呢 反向shell经常被用来绕过防火墙的限制，如阻止入站连接。例如，我有一个专用IP地址为172.31.100.7，我使用代理服务器连接到外部网络。如果我想从网络外部访问 这台机器如1.2.3.4的shell，那么我会用反向外壳用于这一目的。 指定源端口假设你的防火墙过滤除25端口外其它所有端口，你需要使用-p选项指定源端口。 服务器端$nc -l 1567客户端$nc 172.31.100.7 1567 -p 25使用1024以内的端口需要root权限。 该命令将在客户端开启25端口用于通讯，否则将使用随机端口。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[build bind with edns support]]></title>
    <url>%2F2018%2F09%2F23%2Fbuild-bind-with-edns-support%2F</url>
    <content type="text"><![CDATA[download and extract BIND.123$ wget ftp://ftp.isc.org/isc/bind9/9.9.3/bind-9.9.3.tar.gz$ tar xf bind-9.9.3.tar.gz$ cd bind-9.9.3 Download the patch from Wilmer van der Gaast.1$ wget http://wilmer.gaa.st/edns-client-subnet/bind-9.9.3-dig-edns-client-subnet-iana.diff Patch the code, configure (without OpenSSL because we only want dig) and compile.123$ patch -p0 &lt; bind-9.9.3-dig-edns-client-subnet-iana.diff$ ./configure --without-openssl$ make Now you will have dig placed in bin/dig. You can try it this way:1$ ./bin/dig/dig @ns1.google.com www.google.es +client=157.88.0.0/16 Note the CLIENT-SUBNET line in the answer OPT PSEUDOSECTION.&gt;]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unix 环境变量加载顺序]]></title>
    <url>%2F2018%2F09%2F23%2Funix-env-load-order%2F</url>
    <content type="text"><![CDATA[OSXMac系统的环境变量加载顺序为 1/etc/profile -&gt; /etc/paths -&gt; ~/.bash_profile -&gt; ~/.bash_login -&gt; ~/.profile -&gt; ~/.bashrc 特别注意 /etc/paths 中的内容12345/usr/bin/bin/usr/sbin/sbin/usr/local/bin Homebrew 安装的软件，其二进制执行文件都放在/usr/local/bin中，bin 在使用时的查找不是覆盖原则，而是优先查找，所以例如 mac 已经自带了sqlite3，如果 brew 安装后，最新版的 sqlite3 是不会被调用的，因此可以将顺序修改一下以达到目的。 LinuxMac系统的环境变量加载顺序为1/etc/profile -&gt; (~/.bash_profile | ~/.bash_login | ~/.profile) -&gt; ~/.bashrc -&gt; /etc/bashrc -&gt; ~/.bash_logout /usr/bin:usr/sbin 在 /etc/profile 文件中]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 基于权重的平滑轮询算法]]></title>
    <url>%2F2018%2F03%2F19%2Fload-balance-algorithm%2F</url>
    <content type="text"><![CDATA[Nginx 基于权重的轮询算法Nginx基于权重的轮询算法的实现可以参考它的一次代码提交 Upstream: smooth weighted round-robin balancing 它不但实现了基于权重的轮询算法，而且还实现了平滑的算法。所谓平滑，就是在一段时间内，不仅服务器被选择的次数的分布和它们的权重一致，而且调度算法还比较均匀的选择服务器，而不会集中一段时间之内只选择某一个权重比较高的服务器。如果使用随机算法选择或者普通的基于权重的轮询算法，就比较容易造成某个服务集中被调用压力过大。 举个例子，比如权重为 {a:5, b:1, c:1} 的一组服务器，Nginx 的平滑的轮询算法选择的序列为{ a, a, b, a, c, a, a },这显然要比{ c, b, a, a, a, a, a } 序列更平滑，更合理，不会造成对a服务器的集中访问。 Lua 实现每次需要遍历所有的 servers 列表，返回 best server 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869local ceil = math.ceillocal _M = &#123; _VERSION = &quot;0.11&quot; &#125;--[[parameters: - (table) servers - (function) peer_cb(index, server)return: - (table) server - (string) error--]]function _M.next_round_robin_server(servers, peer_cb) local srvs_cnt = #servers if srvs_cnt == 1 then if peer_cb(1, servers[1]) then return servers[1], nil end return nil, &quot;round robin: no servers available&quot; end -- select round robin server local best local max_weight local weight_sum = 0 for idx = 1, srvs_cnt do local srv = servers[idx] -- init round robin state srv.weight = srv.weight or 1 srv.effective_weight = srv.effective_weight or srv.weight srv.current_weight = srv.current_weight or 0 if peer_cb(idx, srv) then srv.current_weight = srv.current_weight + srv.effective_weight weight_sum = weight_sum + srv.effective_weight if srv.effective_weight &lt; srv.weight then srv.effective_weight = srv.effective_weight + 1 end if not max_weight or srv.current_weight &gt; max_weight then max_weight = srv.current_weight best = srv end end end if not best then return nil, &quot;round robin: no servers available&quot; end best.current_weight = best.current_weight - weight_sum return best, nilendfunction _M.free_round_robin_server(srv, failed) if not failed then return end srv.effective_weight = ceil((srv.effective_weight or 1) / 2)endreturn _M]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unix tcpdump 使用技巧]]></title>
    <url>%2F2018%2F03%2F18%2Ftcpdump-using-skill%2F</url>
    <content type="text"><![CDATA[常用 tcpdump 参数解析 -i 指定网卡，一般不清楚网卡设置直接使用 “any” 表示抓取所有网卡 -A 使用 ASCII 码打印收到的每个包 -X 同时以十六进制和 ASCII 打印包 常用抓包实例1234567891011# host 和 port 过滤tcpdump -i any -Ans 0 &quot;src host 1.1.1.1 &amp;&amp; dst host 2.2.2.2 &amp;&amp; dst port 3100&quot;# GETtcpdump -i eth1 &apos;tcp[(tcp[12]&gt;&gt;2):4] = 0x47455420&apos;# POSTtcpdump -i eth1 &apos;tcp[(tcp[12]&gt;&gt;2):4] = 0x504f5354&apos;# TCP 标志位tcpdump -i any -Ans 0 &apos;host 183.214.154.4 &amp;&amp; tcp[tcpflags]=tcp-syn&apos; tcpdump 过滤器目标语法 dst 和 src 表示来源和目的地eg: src host and dst port 逻辑语法 and、or and noteg: src host1 or src host2 包内容过滤proto[x:y] 过滤从x字节开始的y字节数。比如ip[2:2]过滤出3、4字节（第一字节从0开始排 eg:1234tcp[(tcp[12]&gt;&gt;2):4] = 0x47455420tcp[12]&gt;&gt;4&lt;&lt;2 == tcp[12]&gt;&gt;22tcp[12]&gt;&gt;4 拿到 13 字节的 高 4 位，&gt;&gt;2相当于除以 4(32/8)，即偏移的 8 bits 位数 标志位过滤tcp[tcpflags]=tcp-syn TCP Header Format12345678910111213141516171819202122232425 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Port | Destination Port | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Acknowledgment Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | |U|A|P|R|S|F| | | Offset| Reserved |R|C|S|S|Y|I| Window | | | |G|K|H|T|N|N| | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Checksum | Urgent Pointer | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options | Padding | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+Data Offset: 4 bits The number of ```32 bit words``` in the TCP Header. This indicates where the data begins. The TCP header (even one including options) is an integral number of 32 bits long. IP format123456789101112131415 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|Version| IHL |Type of Service| Total Length |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Identification |Flags| Fragment Offset |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Time to Live | Protocol | Header Checksum |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Source Address |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Destination Address |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Options | Padding |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 pprof 和 Flame-Graph 调试 Golang 应用]]></title>
    <url>%2F2018%2F01%2F21%2Fusing-pprof-and-Flame-Graph-debug-Golang-Application%2F</url>
    <content type="text"><![CDATA[前言最近用 Golang 实现了一个日志搜集上报程序(内部称 logger 项目)，线上灰度测试过程发现 logger 占用 CPU 非常高(80% - 100%)。而此项目之前就在线上使用，用于消费 NSQ 任务， CPU 占用一直在 1%，最近的修改只是添加了基于磁盘队列的生产者消费者服务，生产者使用 go-gin 实现了一个 httpserver，接收数据后写入磁盘队列；消费者为单个 goroutine 循环 POST 数据。而 httpserver 压力不大(小于 100 QPS)，不至于占用如此高的 CPU，大致 review 代码后未发现异常，借助 pprof 和 flame-graph 来分析定位问题。 pprofpprof 我理解是 program profile(即程序性能剖析之意)，Golang 提供的两个官方包runtime/pprof，net/http/pprof能方便的采集程序运行的堆栈、goroutine、内存分配和占用、io 等信息的 .prof 文件，然后可以使用 go tool pprof 分析 .prof 文件。两个包的作用是一样的，只是使用方式的差异。 runtime/pprof如果程序为非 httpserver 类型，使用此方式；在 main 函数中嵌入如下代码: 1234567891011121314151617181920212223242526272829303132import &quot;runtime/pprof&quot;var cpuprofile = flag.String(&quot;cpuprofile&quot;， &quot;&quot;， &quot;write cpu profile `file`&quot;)var memprofile = flag.String(&quot;memprofile&quot;， &quot;&quot;， &quot;write memory profile to `file`&quot;)func main() &#123; flag.Parse() if *cpuprofile != &quot;&quot; &#123; f， err := os.Create(*cpuprofile) if err != nil &#123; log.Fatal(&quot;could not create CPU profile: &quot;， err) &#125; if err := pprof.StartCPUProfile(f); err != nil &#123; log.Fatal(&quot;could not start CPU profile: &quot;， err) &#125; defer pprof.StopCPUProfile() &#125; // ... rest of the program ... if *memprofile != &quot;&quot; &#123; f， err := os.Create(*memprofile) if err != nil &#123; log.Fatal(&quot;could not create memory profile: &quot;， err) &#125; runtime.GC() // get up-to-date statistics if err := pprof.WriteHeapProfile(f); err != nil &#123; log.Fatal(&quot;could not write memory profile: &quot;， err) &#125; f.Close() &#125;&#125; 运行程序 1./logger -cpuprofile cpu.prof -memprofile mem.prof 可以得到 cpu.prof 和 mem.prof 文件，使用 go tool pprof 分析。 12go tool pprof logger cpu.profgo tool pprof logger mem.prof net/http/pprof如果程序为 httpserver 类型， 则只需要导入该包: 1import _ &quot;net/http/pprof&quot; 如果 httpserver 使用 go-gin 包，而不是使用默认的 http 包启动，则需要手动添加 /debug/pprof 对应的 handler，github 有封装好的模版: 12345import &quot;github.com/DeanThompson/ginpprof&quot;...router := gin.Default()ginpprof.Wrap(router)... 导入包重新编译程序后运行，在浏览器中访问 http://host:port/debug/pprof 可以看到如下信息，这里 host 和 port 是程序绑定的 host 和 port，例如我自己的 logger 程序，访问如下地址: http://127.0.0.1:4500/debug/pprof/ 12345678910/debug/pprof/profiles:0 block62 goroutine427 heap0 mutex12 threadcreatefull goroutine stack dump 点击对应的 profile 可以查看具体信息，通过浏览器查看的数据不能直观反映程序性能问题，go tool pprof 命令行工具提供了丰富的工具集: 查看 heap 信息 1go tool pprof http://127.0.0.1:4500/debug/pprof/heap 查看 30s 的 CPU 采样信息 1go tool pprof http://127.0.0.1:4500/debug/pprof/profile 其他功能使用参见官方 net/http/pprof 库 pprof CPU 分析采集 profile 数据之后，可以分析 CPU 热点代码。执行下面命令： 1go tool pprof http://127.0.0.1:4500/debug/pprof/profile 会采集 30s 的 profile 数据，之后进入终端交互模式，输入 top 指令。 1234567891011121314151617181920212223~ # go tool pprof http://127.0.0.1:4500/debug/pprof/profileFetching profile over HTTP from http://127.0.0.1:4500/debug/pprof/profileSaved profile in /home/vagrant/pprof/pprof.logger.samples.cpu.012.pb.gzFile: loggerType: cpuTime: Jan 19， 2018 at 2:01pm (CST)Duration: 30s， Total samples = 390ms ( 1.30%)Entering interactive mode (type &quot;help&quot; for commands， &quot;o&quot; for options)(pprof) topShowing nodes accounting for 360ms， 92.31% of 390ms totalShowing top 10 nodes out of 74 flat flat% sum% cum cum% 120ms 30.77% 30.77% 180ms 46.15% compress/flate.(*compressor).findMatch /usr/local/go/src/compress/flate/deflate.go 100ms 25.64% 56.41% 310ms 79.49% compress/flate.(*compressor).deflate /usr/local/go/src/compress/flate/deflate.go 60ms 15.38% 71.79% 60ms 15.38% compress/flate.matchLen /usr/local/go/src/compress/flate/deflate.go 20ms 5.13% 76.92% 20ms 5.13% compress/flate.(*huffmanBitWriter).indexTokens /usr/local/go/src/compress/flate/huffman_bit_writer.go 10ms 2.56% 79.49% 10ms 2.56% compress/flate.(*huffmanBitWriter).writeTokens /usr/local/go/src/compress/flate/huffman_bit_writer.go 10ms 2.56% 82.05% 10ms 2.56% hash/adler32.update /usr/local/go/src/hash/adler32/adler32.go 10ms 2.56% 84.62% 10ms 2.56% runtime.futex /usr/local/go/src/runtime/sys_linux_amd64.s 10ms 2.56% 87.18% 10ms 2.56% runtime.memclrNoHeapPointers /usr/local/go/src/runtime/memclr_amd64.s 10ms 2.56% 89.74% 10ms 2.56% runtime.pcvalue /usr/local/go/src/runtime/symtab.go 10ms 2.56% 92.31% 10ms 2.56% runtime.runqput /usr/local/go/src/runtime/runtime2.go(pprof) 从统计可以 top5 操作全是数据压缩操作， logger 程序本身开启了压缩等级为 9 的 gzip 压缩，如果希望减少压缩 CPU 占用，可以调整压缩等级。 pprof mem 分析同时 pprof 也支持内存相关数据分析 --inuse_space 分析常驻内存1go tool pprof -alloc_space http://127.0.0.1:4500/debug/pprof/heap 1234567891011121314151617181920212223~ # go tool pprof -alloc_space http://127.0.0.1:4500/debug/pprof/heapFetching profile over HTTP from http://127.0.0.1:4500/debug/pprof/heapSaved profile in /home/vagrant/pprof/pprof.logger.alloc_objects.alloc_space.inuse_objects.inuse_space.006.pb.gzFile: loggerType: alloc_spaceTime: Jan 19， 2018 at 2:21pm (CST)Entering interactive mode (type &quot;help&quot; for commands， &quot;o&quot; for options)(pprof) topShowing nodes accounting for 47204.90MB， 99.16% of 47606.01MB totalDropped 230 nodes (cum &lt;= 238.03MB)Showing top 10 nodes out of 39 flat flat% sum% cum cum%28290.79MB 59.43% 59.43% 28290.79MB 59.43% bytes.makeSlice /usr/local/go/src/bytes/buffer.go 8706.78MB 18.29% 77.72% 10082.12MB 21.18% compress/flate.NewWriter /usr/local/go/src/compress/flate/deflate.go 8559.74MB 17.98% 95.70% 8559.74MB 17.98% github.com/nsqio/go-diskqueue.(*diskQueue).readOne /home/vagrant/go/src/github.com/nsqio/go-diskqueue/diskqueue.go 1343.78MB 2.82% 98.52% 1343.78MB 2.82% compress/flate.(*compressor).init /usr/local/go/src/compress/flate/deflate.go 298.81MB 0.63% 99.15% 298.81MB 0.63% github.com/nsqio/go-nsq.ReadResponse /home/vagrant/go/src/github.com/nsqio/go-nsq/protocol.go 2MB 0.0042% 99.15% 12097.28MB 25.41% main.(*PostPublisher).Publish /home/vagrant/logger/src/handler.go 1.50MB 0.0032% 99.15% 26358.53MB 55.37% io/ioutil.readAll /usr/local/go/src/io/ioutil/ioutil.go 1MB 0.0021% 99.16% 26378.74MB 55.41% github.com/gin-gonic/gin.LoggerWithWriter.func1 /home/vagrant/go/src/github.com/gin-gonic/gin/logger.go 0.50MB 0.0011% 99.16% 26434.42MB 55.53% net/http.(*conn).serve /usr/local/go/src/net/http/server.go 0 0% 99.16% 26357.03MB 55.36% bytes.(*Buffer).ReadFrom /usr/local/go/src/bytes/buffer.go(pprof) --alloc_objects 分析临时内存1go tool pprof -inuse_space http://127.0.0.1:4500/debug/pprof/heap 12345678910111213141516171819202122~ # go tool pprof -inuse_space http://127.0.0.1:4500/debug/pprof/heapFetching profile over HTTP from http://127.0.0.1:4500/debug/pprof/heapSaved profile in /home/vagrant/pprof/pprof.logger.alloc_objects.alloc_space.inuse_objects.inuse_space.007.pb.gzFile: loggerType: inuse_spaceTime: Jan 19， 2018 at 2:24pm (CST)Entering interactive mode (type &quot;help&quot; for commands， &quot;o&quot; for options)(pprof) topShowing nodes accounting for 20441.23kB， 100% of 20441.23kB totalShowing top 10 nodes out of 35 flat flat% sum% cum cum%18071.75kB 88.41% 88.41% 18071.75kB 88.41% bytes.makeSlice /usr/local/go/src/bytes/buffer.go 815.27kB 3.99% 92.40% 815.27kB 3.99% github.com/nsqio/go-diskqueue.(*diskQueue).readOne /home/vagrant/go/src/github.com/nsqio/go-diskqueue/diskqueue.go 528.17kB 2.58% 94.98% 528.17kB 2.58% regexp.(*bitState).reset /usr/local/go/src/regexp/backtrack.go 514kB 2.51% 97.50% 514kB 2.51% net/http.newBufioWriterSize /usr/local/go/src/bufio/bufio.go 512.05kB 2.50% 100% 512.05kB 2.50% net/http.(*persistConn).roundTrip /usr/local/go/src/net/http/transport.go 0 0% 100% 528.17kB 2.58% _/home/vagrant/logger/src/parser.ParserLogForMarco /home/vagrant/logger/src/parser/parser.go 0 0% 100% 528.17kB 2.58% bytes.(*Buffer).ReadFrom /usr/local/go/src/bytes/buffer.go 0 0% 100% 17543.58kB 85.82% bytes.(*Buffer).Write /usr/local/go/src/bytes/buffer.go 0 0% 100% 17543.58kB 85.82% bytes.(*Buffer).grow /usr/local/go/src/bytes/buffer.go 0 0% 100% 528.17kB 2.58% github.com/gin-gonic/gin.(*Context).Next /home/vagrant/go/src/github.com/gin-gonic/gin/context.go(pprof) 通过常驻内存和临时内存分配 top 值，可以查看当前程序的内存占用情况和热点内存使用的代码，结合代码分析热点代码是否存在 bug、是否有优化的空间。 go-torch通过上面的 go tool pprof 工具和 top 指令，我们能定位出程序的热点代码，但缺乏对程序运行情况的整体感知，能不能有类似火焰图的效果让我们对整个堆栈统计信息有个一目了然的效果呢？这里要感谢 uber 开源的工具 go-torch，能让我们将 profile 信息转换成火焰图，具体安装和使用过程见项目的介绍。 安装好 go-torch 后，运行 1go-torch -u http://127.0.0.1:4500 生成 CPU 火焰图 从图中能一眼看到 publish 函数中的压缩操作占了 70% 左右的 CPU。 而 gin httpserver 只占用了 2% 左右的 CPU， 和我们使用 go tool pprof 的 top 命令分析的结果一致。 默认情况下 go-torch 采集的是 CPU 的 profile， 这里介绍下 mem 火焰图的采集。 inuse_space 火焰图1go-torch -inuse_space http://127.0.0.1:4500/debug/pprof/heap --colors=mem alloc_space 火焰图1go-torch -alloc_space http://127.0.0.1:4500/debug/pprof/heap --colors=mem logger 100% CPU 分析前面介绍了 go tool pprof 和火焰图的使用方法，这里使用火焰图复现 logger 100% CPU 问题。 先看现象， 用 wrk 压测 logger 1wrk -t1 -c100 -d30 --script=post.lua &apos;http://127.0.0.1:4500/marco/log&apos; 查看 CPU 占用情况 采集 30s 的 CPU profile 火焰图 图中红色标记部分 startSink 函数中 runtime.selectgo 消耗了大量 CPU， 而 runtime.selectgo 上面只有 runtime.sellock 和 runtime.selunlock 两个操作，即大量 CPU 耗费在 select 操作上，火焰图呈秃顶状态，即瓶颈所在。 查看 startSink 实现 1234567891011121314151617181920212223242526272829303132333435363738394041for &#123; if exit == true &#123; return &#125; if moveforward &#123; fakeRead = readChan &#125; else &#123; fakeRead = nil &#125; select &#123; case read := &lt;-fakeRead: count++ buf.Write(read) case &lt;-done: DiskQueue.Close() exit = true default: //pass &#125; if count == GlobalConf.CntBatch || exit == true &#123; hostPoolResponse := pool.Get() addr := hostPoolResponse.Host() err := handler.Publish(fmt.Sprintf(&quot;%s%s&quot;， addr， SinkConf.Uri)， buf.Bytes()) hostPoolResponse.Mark(err) if err != nil &#123; Log.Error(&quot;%s&quot;， err.Error()) moveforward = false time.Sleep(1 * time.Second) continue &#125; else &#123; moveforward = true &#125; buf.Reset() count = 0 &#125;&#125; 本希望通过 moveforward 来控制 fakeRead 是否取值，而如果 fakeRead 为 nil 时， 整个 select 会一直阻塞，所以加上了 default 操作，让 select 变成非阻塞，但因为一直没有读取内容，count 没有增加而不会触发 sleep 操作。最终导致非阻塞的 select 一直空转循环，类似一个空 while 循环，占用了大量 CPU。 优化改用其他方法实现这部分逻辑，这里不再贴出来了，重在分享发现问题的过程，改进后的火焰图在前面已给出。 总结Golang 应用通常只要能编译通过，很少有运行时问题；而当应用遇到高CPU 、高内存占用或者作为 http 服务端响应时间长，QPS 上不去等，且不能 code review 解决时，可以尝试使用pprof 和 Flame-Graph 来分析定位问题，有奇效。当然 Golang 程序的调试及调优还有很多方法，比如直接结合go test 和 benchmark通过测用例分析热点代码、使用go pprof分析汇编代码等。]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 使用 grep 找回误删文件]]></title>
    <url>%2F2016%2F09%2F26%2Ffind-mistake-deleted-file-by-grep%2F</url>
    <content type="text"><![CDATA[在操作 linux 过程中，经常由于错误的操作误删除文件，则可以使用 grep 操作找回 命令1$ grep -a -B 10 -A 100 'vpsee.com' /dev/sda1 &gt; tmp.txt -a表示将磁盘 /dev/sda1 当做二进制文件来读 -B 10 -A 100 表示如果匹配到 vpsee.com，则打印前 10 行和后 100 行 匹配结果重定向到 tmp.txt note 在发现误删除文件后，尽量减少其他的文件操作避免已删除的文件被覆盖。 grep 操作耗费会占用大量的内存空间，如果发现 grep 失败（虚拟机中），可多分配内存重试。 可能删除的文件不在 /dev/sda1 磁盘上，可使用 df 来查看是否有其他磁盘。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua and 和 or 踩坑]]></title>
    <url>%2F2016%2F09%2F25%2Flua-and-or%2F</url>
    <content type="text"><![CDATA[lua and or 操作 a and b如果a为false，则返回 a；否则返回 b a or b如果 a 为 true，则返回 a；否则返回 b C语言中的语句：x = a? b : c，在Lua中可以写成：x = a and b or c 存在的问题12debug = 0(or 1)step = debug and 0 or 80 则无论 debug 取 0 还是 1，step 输出都是 0 当 debug 为0 120 and 0 = 00 or 80 = 0 当 debug 为 1 120 and 0 = 00 or 80 = 0 错误原因lua将 0 认为是 true 解决方法定义 debug = true or false1step = debug and 0 or 80 则当 debug 为 false 时候，step 为 80]]></content>
      <tags>
        <tag>Lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux core 设置]]></title>
    <url>%2F2016%2F09%2F25%2Fcore-dump-setting%2F</url>
    <content type="text"><![CDATA[linux 程序异常退出时，内核会生成 core 文件，通过 GDB 查看 core 文件可以定位程序异常退出时候的堆栈信息，指示出错的位置。 查看 core 文件是否打开1$ ulimit -c 如果结果为0，则表示系统关闭了该功能 开启 core在当前 shell 设置1$ ulimit -c unlimited 为整个用户设置1$ cat ulimit-c unlimited &gt; ~/.zshrc &amp;&amp; source ~/.zshrc core 设置文件名是否带pid标识1$ echo "1" &gt; /proc/sys/kernel/core_uses_pid core 文件格式为 corename_with_format.pid 1$ echo "0" &gt; /proc/sys/kernel/core_uses_pid core 文件格式为 corename_with_format 保存位置及格式设置查看当前设置1$ cat /proc/sys/kernel/core_pattern 位置及格式1$ echo "/corefile_path/core-%e-%p-%t" &gt; /proc/sys/kernel/core_pattern 具体参数含义 参数 描述 %p pid %u current uid %g current gid %s signal that caused the coredump %t UNIX time that the coredump occurred %h hostname where the coredump happened %e coredumping executable name]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Qucik Start]]></title>
    <url>%2F2016%2F09%2F20%2Fhexo-quick-start%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
